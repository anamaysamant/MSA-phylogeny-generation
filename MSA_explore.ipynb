{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb044b92-503d-4560-838e-d85387c5dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import esm\n",
    "import torch\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bccbc9-b1c3-4615-9253-b5144770d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional, Dict, NamedTuple, Union, Callable\n",
    "import itertools\n",
    "import os\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from Bio import SeqIO, Phylo\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import squareform, pdist, cdist\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f72829-bbe4-40af-9fce-4e39835aecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "deletekeys = dict.fromkeys(string.ascii_lowercase)\n",
    "deletekeys[\".\"] = None\n",
    "deletekeys[\"*\"] = None\n",
    "translation = str.maketrans(deletekeys)\n",
    "\n",
    "def read_sequence(filename: str) -> Tuple[str, str]:\n",
    "    \"\"\" Reads the first (reference) sequences from a fasta or MSA file.\"\"\"\n",
    "    record = next(SeqIO.parse(filename, \"fasta\"))\n",
    "    return record.description, str(record.seq)\n",
    "\n",
    "def remove_insertions(sequence: str) -> str:\n",
    "    \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n",
    "    return sequence.translate(translation)\n",
    "\n",
    "def read_msa(filename: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\" Reads the sequences from an MSA file, automatically removes insertions.\"\"\"\n",
    "    return [(record.description, remove_insertions(str(record.seq))) for record in SeqIO.parse(filename, \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9604eb0-23ff-4b08-ac9a-36d0ed1d621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSA_filename = \"PF00004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69f06f-fba7-4142-856e-384896453e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### In case sequences don't have names\n",
    "\n",
    "# x = SeqIO.parse(f\"{MSA_filename}.fasta\", \"fasta\")\n",
    "\n",
    "# x = [SeqRecord(Seq(remove_insertions(str(record.seq))), id = f\"seq{i}\", description=f\"seq{i}\") for i,record in enumerate(x)]\n",
    "\n",
    "# with open(\"1a3a_1_A_named.a3m\", \"w\") as output_handle:\n",
    "#     SeqIO.write(x, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9075e2-74fd-41e5-855e-979d902948a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seqs = [(record.description, remove_insertions(str(record.seq))) for record in SeqIO.parse(f\"{MSA_filename}.fasta\", \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e9f218-26fe-4485-bf4d-03d202182ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_select(msa: List[Tuple[str, str]], num_seqs: int, mode: str = \"max\") -> List[Tuple[str, str]]:\n",
    "    assert mode in (\"max\", \"min\")\n",
    "    if len(msa) <= num_seqs:\n",
    "        return msa\n",
    "    \n",
    "    array = np.array([list(seq) for _, seq in msa], dtype=np.bytes_).view(np.uint8)\n",
    "\n",
    "    optfunc = np.argmax if mode == \"max\" else np.argmin\n",
    "    all_indices = np.arange(len(msa))\n",
    "    indices = [0]\n",
    "    pairwise_distances = np.zeros((0, len(msa)))\n",
    "    for _ in range(num_seqs - 1):\n",
    "        dist = cdist(array[indices[-1:]], array, \"hamming\")\n",
    "        pairwise_distances = np.concatenate([pairwise_distances, dist])\n",
    "        shifted_distance = np.delete(pairwise_distances, indices, axis=1).mean(0)\n",
    "        shifted_index = optfunc(shifted_distance)\n",
    "        index = np.delete(all_indices, indices)[shifted_index]\n",
    "        indices.append(index)\n",
    "    indices = sorted(indices)\n",
    "    return [msa[idx] for idx in indices]\n",
    "\n",
    "def Seq_tuples_to_fasta(sequences, file_name):\n",
    "    MSA_SeqRecords = [SeqRecord(Seq(record[1]), id = record[0], name= record[0], description= record[0]) for record in sequences]\n",
    "    with open(f\"{file_name}.fasta\", \"w\") as output_handle:\n",
    "        SeqIO.write(MSA_SeqRecords, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3df96-6579-489a-ae5f-6faf4db92110",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seqs = 100\n",
    "sampled_MSA_tuples = greedy_select(all_seqs, num_seqs=num_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f946ad7-484a-41a8-90af-c834011b15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_MSA_SeqRecords = [SeqRecord(Seq(record[1]), id = record[0], name= record[0], description= record[0]) for record in sampled_MSA_tuples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72aed2-c28c-41b6-80a3-aa279a08b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{MSA_filename}_sampled_{num_seqs}.fasta\", \"w\") as output_handle:\n",
    "    SeqIO.write(sampled_MSA_SeqRecords, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c021fb7-845f-43b8-aa2a-098349134450",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Phylo.read(f\"{MSA_filename}_sampled_{num_seqs}.tree\",\"newick\")\n",
    "tree.root_at_midpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d7ed68-4107-41cd-8c00-0762733e006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phylo.write(tree,f\"{MSA_filename}_sampled_{num_seqs}_rooted.tree\",\"newick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d748f-ef31-4b1d-935f-4f39f3fd4c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree2 = Phylo.read(f\"{MSA_filename}.tree\",\"newick\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3462b8cc-e4e5-4c64-9297-b8b3a402f58c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree2.root_with_outgroup(\"sample426\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80962e8-9169-4971-812e-61f92b57ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phylo.write(tree2,f\"{MSA_filename}_rooted.tree\",\"newick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0313b277-6783-4584-ba32-ec37e06ccbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree2_rooted = Phylo.read(f\"{MSA_filename}_sampled_100_rooted.tree\",\"newick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6541f58-ec1c-4f38-806b-533df6bdf29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phylo.draw(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23008981-c676-4c86-ba3c-d7ae803a22b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, alphabet = esm.pretrained.esm_msa1b_t12_100M_UR50S()\n",
    "model = model.to(device)\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa9b1f-3917-4257-9642-4d1c464392a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,batch_tokens = batch_converter([sampled_MSA_tuples])\n",
    "batch_tokens = batch_tokens.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f474f-02cf-4ce6-ab72-0ed6cad36fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(batch_tokens, need_head_weights = False, return_contacts = False)[\"logits\"]\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970aed7-8528-4e7b-b640-2f18d42bfa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "probs = softmax(logits).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a587d2-88c3-453d-b2ee-d32dea42590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_tokens = batch_tokens.cpu().numpy()\n",
    "MSA_prob_matrix = np.zeros((probs.shape[1],probs.shape[2]))\n",
    "for i in range(probs.shape[1]):\n",
    "    for j in range(probs.shape[2]):\n",
    "        char_index = int(numpy_tokens[0,i,j])\n",
    "        MSA_prob_matrix[i,j] = probs[0,i,j,char_index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d165c8-615f-4bb1-b0a0-694a865bea51",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def prob_calculator(batch_tokens, selected_pos, method = \"minimal\", masked = False):\n",
    "\n",
    "        softmax = torch.nn.Softmax(dim = -1)\n",
    "\n",
    "        batch_tokens_copy = batch_tokens.clone()\n",
    "        original_char_index = batch_tokens[0,0,selected_pos] \n",
    "\n",
    "        n_cols = batch_tokens.shape[2]\n",
    "        n_rows = batch_tokens.shape[1]\n",
    "        \n",
    "        if masked == True:\n",
    "            batch_tokens_copy[0,0,selected_pos] = 32\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            # logits = self.model(batch_tokens_copy, need_head_weights = False, return_contacts = False)[\"logits\"]\n",
    "            # embeds = self.msa_light(batch_tokens, repr_layers = [12])[\"representations\"][12]\n",
    "\n",
    "            # original_char_prob = (softmax(self.msa_lm_head(self.msa_light(batch_tokens_copy)[0,0,selected_pos,:])).cpu().numpy())[original_char_index]\n",
    "            original_prob_arr = (softmax(model(batch_tokens_copy)[\"logits\"][0,0,selected_pos,:]).cpu().numpy())\n",
    "            original_char_prob = original_prob_arr[original_char_index]\n",
    "\n",
    "            print(original_prob_arr)\n",
    "        \n",
    "            if method == \"minimal\":\n",
    "\n",
    "                return np.log(original_char_prob)\n",
    "                  \n",
    "            if method == \"full\" or method == \"row\":\n",
    "\n",
    "                # probs = softmax(self.msa_lm_head(self.msa_light(batch_tokens_copy)[0,0,:,:])).cpu().numpy()\n",
    "                probs = softmax(model(batch_tokens_copy)[\"logits\"][0,0,:,:]).cpu().numpy()\n",
    "                          \n",
    "                log_prob_row = 0\n",
    "                \n",
    "                for i in range(1,n_cols):\n",
    "                    char_index = batch_tokens[0,0,i]\n",
    "                    log_prob_row += np.log(probs[i,char_index])\n",
    "    \n",
    "                if method == \"row\":\n",
    "    \n",
    "                    return log_prob_row\n",
    "                                               \n",
    "            if method == \"full\" or method == \"col\":\n",
    "\n",
    "                log_prob_col = 0\n",
    "    \n",
    "                # probs = softmax(self.msa_lm_head(self.msa_light(batch_tokens_copy)[0,:,selected_pos,:])).cpu().numpy()\n",
    "                probs = softmax(model(batch_tokens_copy)[\"logits\"][0,:,selected_pos,:]).cpu().numpy()\n",
    "\n",
    "                for i in range(n_rows):\n",
    "                    char_index = batch_tokens[0,i,selected_pos]\n",
    "                    log_prob_col += np.log(probs[i,char_index])\n",
    "    \n",
    "                if method == \"col\":\n",
    "    \n",
    "                    return log_prob_col\n",
    "    \n",
    "            log_total_prob = log_prob_row + log_prob_col - np.log(original_char_prob)\n",
    "\n",
    "        return log_total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3991ac1-81cf-4e47-96ef-89a368308c61",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "previous_sequence_batch_tokens = batch_tokens[0,:1,:].unsqueeze(0)\n",
    "constant_batch_tokens = batch_tokens[0,1:,:].unsqueeze(0)\n",
    "n_cols = batch_tokens.shape[2]\n",
    "\n",
    "c_mutation = 0\n",
    "\n",
    "while c_mutation < 10:\n",
    "    stacked_batch_tokens = torch.cat((previous_sequence_batch_tokens, constant_batch_tokens), dim = 1)\n",
    "    selected_pos = np.random.randint(1, n_cols + 1)\n",
    "    \n",
    "    orig_log_prob = prob_calculator(stacked_batch_tokens, selected_pos, method=\"minimal\", masked=True)\n",
    "    orig_prob = np.exp(orig_log_prob)\n",
    "    \n",
    "    original_character_int = int(previous_sequence_batch_tokens[0,0, selected_pos].cpu().numpy())        \n",
    "    \n",
    "    proposed_mutation = np.random.randint(4, 24)\n",
    "    \n",
    "    if proposed_mutation >= original_character_int and proposed_mutation != 23:\n",
    "        proposed_mutation += 1\n",
    "    elif proposed_mutation == 23:\n",
    "        proposed_mutation = 30\n",
    "    \n",
    "    modified_sequence_batch_tokens = previous_sequence_batch_tokens.clone()\n",
    "    modified_sequence_batch_tokens[0,0,selected_pos] = proposed_mutation\n",
    "    modified_stacked_batch_tokens = torch.cat((modified_sequence_batch_tokens, constant_batch_tokens), dim = 1)\n",
    "\n",
    "    assert int((modified_stacked_batch_tokens != stacked_batch_tokens).sum().cpu().numpy()) == 1\n",
    "\n",
    "    assert modified_stacked_batch_tokens[0,0,selected_pos] != stacked_batch_tokens[0,0,selected_pos]\n",
    "    \n",
    "    new_log_prob = prob_calculator(modified_stacked_batch_tokens, selected_pos, method=\"minimal\", masked=True)\n",
    "    new_prob = np.exp(new_log_prob)\n",
    "    \n",
    "    de = new_log_prob - orig_log_prob\n",
    "                    \n",
    "    if True:\n",
    "        previous_sequence_batch_tokens = modified_sequence_batch_tokens.clone()\n",
    "        c_mutation += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53994b0-b413-4a6f-904f-73b1c6bbb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_state_dict = {}\n",
    "# for name, param in model.state_dict().items():\n",
    "#     if not (name.startswith(\"lm_head\") or name.startswith(\"contact_head\")):\n",
    "#         base_state_dict[name] = param\n",
    "\n",
    "# lm_head_state_dict = {}\n",
    "# for name, param in model.state_dict().items():\n",
    "#     if name.startswith(\"lm_head\") or name == \"embed_tokens.weight\":\n",
    "#         lm_head_state_dict[name] = param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5dad2d-8793-4178-a8ba-8e54a58a2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from msa_light import MSATransformer\n",
    "# from msa_lm_head import MSATransformer_lm_head\n",
    "# from tokenization import Vocab\n",
    "\n",
    "# msa_light = MSATransformer(vocab = Vocab.from_esm_alphabet(alphabet))\n",
    "# msa_light = msa_light.to(device)\n",
    "\n",
    "# msa_lm_head = MSATransformer_lm_head(vocab = Vocab.from_esm_alphabet(alphabet))\n",
    "# msa_lm_head = msa_lm_head.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1255dc-35d8-4883-aa6f-9a09a5319d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msa_light.load_state_dict(base_state_dict, strict=True)\n",
    "# msa_lm_head.load_state_dict(lm_head_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8263b0f0-6157-45fd-9560-f2e56bc6be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48710ccf-1b50-4267-be46-bb1a566848a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "\n",
    "# cython: language_level=3, boundscheck=False, wraparound=False, initializedcheck=False, cdivision=True\n",
    "# distutils: extra_compile_args=-fopenmp\n",
    "# distutils: extra_link_args=-fopenmp\n",
    "\n",
    "import numpy as np\n",
    "cimport cython\n",
    "from libc.stdlib cimport RAND_MAX\n",
    "from libc.stdlib cimport rand, srand\n",
    "from posix.stdlib cimport drand48\n",
    "from generation_sequence cimport exp\n",
    "from libc.time cimport time\n",
    "from cython.parallel import prange\n",
    "\n",
    "cdef class Creation_MSA_Generation:\n",
    "\n",
    "    cdef double[:,::1] Field\n",
    "    cdef double[:,:,:,::1] Coupling\n",
    "    cdef int Number_state_spin\n",
    "    cdef int Number_of_Node\n",
    "    cdef int seq_counter\n",
    "    \n",
    "    def __init__(self, double[:,::1] Field, double[:,:,:,::1] Coupling ):\n",
    "\n",
    "        self.Number_of_Node = np.intc(Field.shape[0])\n",
    "        self.Number_state_spin = np.intc(Field.shape[1])\n",
    "        self.Field = Field\n",
    "        self.Coupling = Coupling\n",
    "        self.seq_counter = 0\n",
    "        srand(<unsigned int>time(NULL))\n",
    "        \n",
    "    def msa_no_phylo(self, int n_sequences, int n_flip_equi):\n",
    "        cdef:\n",
    "            int index_msa\n",
    "            char[:,::1] msa = np.random.randint(0,high=self.Number_state_spin, \n",
    "                                size = (n_sequences,self.Number_of_Node)\n",
    "                                ,dtype = np.int8)\n",
    "        for index_msa in prange(msa.shape[0],nogil=True,schedule='dynamic'):\n",
    "            self.mcmc(n_flip_equi, msa[index_msa])\n",
    "        return np.asarray(msa)\n",
    "                \n",
    "    def msa_phylo(self, int n_generations, int n_mutations_generation, int flip_before_start):\n",
    "        cdef:\n",
    "            char[::1] l_spin = np.random.randint(0,\n",
    "                                                 high=self.Number_state_spin\n",
    "                                                 ,size = ( self.Number_of_Node)\n",
    "                                                ,dtype = np.int8)\n",
    "            char[:,::1] msa = np.zeros((int(2**n_generations),self.Number_of_Node)\n",
    "                                ,dtype = np.int8)\n",
    "            int generation,index_sequence\n",
    "        self.seq_counter = 0\n",
    "        self.mcmc(flip_before_start, l_spin)     \n",
    "        msa[0] = l_spin\n",
    "        for generation in range(1,n_generations+1):\n",
    "            msa[int(2**(generation-1)):int(2**generation),:] = msa[0:int(2**(generation-1)),:]\n",
    "            for index_sequence in range(int(2**generation)):\n",
    "                self.mcmc(n_mutations_generation, msa[index_sequence])\n",
    "        return np.asarray(msa)\n",
    "    \n",
    "    def msa_tree_phylo(self, clade_root, int flip_before_start, double neff = 1.0):\n",
    "        cdef :\n",
    "            char[::1] first_sequence = np.random.randint(0,high=self.Number_state_spin\n",
    "                                                         ,size = ( self.Number_of_Node)\n",
    "                                                         ,dtype = np.int8)  \n",
    "            #char[:,::1] msa = np.random.randint(0,high=self.Number_state_spin, \n",
    "            #                                    size = (len(clade_root.get_terminals()),self.Number_of_Node)\n",
    "            #                                    ,dtype = np.int8)\n",
    "            char[:,::1] msa = np.zeros((len(clade_root.get_terminals()),self.Number_of_Node), dtype=np.int8)\n",
    "        self.mcmc(flip_before_start, first_sequence)\n",
    "        return np.asarray(self.msa_tree_phylo_recur(clade_root, first_sequence, msa, neff))\n",
    "    \n",
    "    cdef char[:,::1] msa_tree_phylo_recur(self, clade_root, char[::1] previous_sequence, char[:,::1] msa, double neff):\n",
    "        cdef:\n",
    "            char[::1] new_sequence = np.zeros((previous_sequence.shape[0]),dtype=np.int8)\n",
    "            int n_mutations\n",
    "        b = clade_root.clades\n",
    "        if len(b)>0:\n",
    "            for clade in b:\n",
    "                #Mutation on previous_sequences\n",
    "                new_sequence[:] = previous_sequence\n",
    "                n_mutations = int(clade.branch_length*new_sequence.shape[0]*neff)\n",
    "                self.mcmc(n_mutations, new_sequence)\n",
    "                self.msa_tree_phylo_recur(clade, new_sequence, msa, neff)\n",
    "        else:\n",
    "            # n_mutations = int(clade_root.branch_length*previous_sequence.shape[0]*neff)\n",
    "            # self.mcmc(n_mutations, previous_sequence)\n",
    "            msa[self.seq_counter,:] = previous_sequence\n",
    "            self.seq_counter += 1\n",
    "        return msa\n",
    "    \n",
    "    def hamiltonian(self,char[::1] L_Spin):\n",
    "        cdef:\n",
    "            int node_i,index_neighboor\n",
    "            double hamiltonian = 0.0\n",
    "        for node_i in range(self.Number_of_Node-1):\n",
    "            hamiltonian -= self.Field[node_i,L_Spin[node_i]]\n",
    "            for index_neighboor in range(node_i+1,self.Number_of_Node):\n",
    "                hamiltonian -= self.Coupling[node_i,index_neighboor,L_Spin[node_i],L_Spin[index_neighboor]]\n",
    "        return hamiltonian \n",
    "  \n",
    "    cdef inline void mcmc(self, int Number_of_Mutation, char[::1] L_Spin) nogil:  \n",
    "        cdef:\n",
    "            int selected_node, new_state, c_mutation = 0\n",
    "            double Prob, de\n",
    "        while c_mutation<Number_of_Mutation:   \n",
    "            selected_node = randint(0,self.Number_of_Node)\n",
    "            new_state = randint(0,self.Number_state_spin-1)\n",
    "            if new_state >= L_Spin[selected_node]:\n",
    "                new_state += 1 \n",
    "            de = (\n",
    "                self.Pseudo_Hamiltonian(selected_node, new_state, L_Spin) -\n",
    "                self.Pseudo_Hamiltonian(selected_node, L_Spin[selected_node], L_Spin)\n",
    "                 )\n",
    "            if de>=0 or (rand() / (RAND_MAX + 1.0)) < exp(de):\n",
    "                L_Spin[selected_node]= new_state\n",
    "                c_mutation += 1\n",
    "\n",
    "    cdef inline double Pseudo_Hamiltonian(self, int node, int state_node, char[::1] L_Spin) nogil:\n",
    "        cdef:\n",
    "            int i\n",
    "            double hamiltonian = self.Field[node,state_node] - self.Coupling[node,node,state_node,L_Spin[node]]\n",
    "        for i in range(L_Spin.shape[0]):\n",
    "            hamiltonian += self.Coupling[node,i,state_node,L_Spin[i]]\n",
    "        return hamiltonian \n",
    "\n",
    "cdef inline int randint(int lower, int upper) nogil:\n",
    "\n",
    "    return rand() % (upper - lower ) + lower \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1576ac-dff8-4508-a938-5a83df41afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_bmDCA = np.load(\"PF00004_h.npy\")\n",
    "couplings_bmDCA = np.load(\"PF00004_J.npy\")\n",
    "\n",
    "MSA_gen_obj_Potts = Creation_MSA_Generation(Coupling = couplings_bmDCA, Field =  fields_bmDCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f197a90c-6894-4e72-9ff0-1afbf62a777a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "    def msa_no_phylo(self, n_sequences, n_flip_equi):\n",
    "\n",
    "        cdef:\n",
    "            int char_index, seq_index, i, index\n",
    "        \n",
    "        output_MSA = []\n",
    "        \n",
    "        for index in range(self.n_rows):\n",
    "\n",
    "            MSA = self.original_MSA.copy()\n",
    "            \n",
    "            start_seq = MSA[index]\n",
    "            del MSA[index]\n",
    "            MSA = [start_seq] + MSA\n",
    "\n",
    "            _,_,self.constant_batch_tokens = self.batch_converter([self.original_MSA[1:]])\n",
    "            self.constant_batch_tokens = self.constant_batch_tokens.to(self.device)\n",
    "        \n",
    "            _,_,self.start_seq_batch_tokens = self.batch_converter([self.original_MSA[:1]])\n",
    "            self.start_seq_batch_tokens = self.start_seq_batch_tokens.to(self.device)\n",
    "            \n",
    "            new_batch_tokens = self.mcmc(n_flip_equi, self.start_seq_batch_tokens)\n",
    "\n",
    "            final_seq = \"\"\n",
    "            for i in range(1,self.n_cols+1):\n",
    "    \n",
    "                char_index = int(new_batch_tokens[0,0,i].cpu().numpy())\n",
    "                char = self.model_alphabet_mapping_inv[char_index]\n",
    "                final_seq += char\n",
    "                \n",
    "            seq_index = len(output_MSA)\n",
    "            output_MSA.append((f\"seq{seq_index}\",final_seq))      \n",
    "            \n",
    "        \n",
    "        ### return to original state\n",
    "        \n",
    "        _,_,self.constant_batch_tokens = self.batch_converter([self.original_MSA[1:]])\n",
    "        self.constant_batch_tokens = self.constant_batch_tokens.to(self.device)\n",
    "        \n",
    "        _,_,self.start_seq_batch_tokens = self.batch_converter([self.original_MSA[:1]])\n",
    "        self.start_seq_batch_tokens = self.start_seq_batch_tokens.to(self.device)\n",
    "\n",
    "        ###\n",
    "\n",
    "        return output_MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97673d-f064-4cde-b50a-f17db561ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list('LLVHGPPGTGKTTLCKALCQKLSVRIIELSCARIFSKWFGESSKNISIVFKDIEELLGII'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609700a0-52de-45b2-b8c6-0b764049596e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport cython\n",
    "from libc.stdlib cimport RAND_MAX, rand, srand\n",
    "from libc.math cimport exp\n",
    "import torch\n",
    "import esm\n",
    "from msa_light import MSATransformer\n",
    "from msa_lm_head import MSATransformer_lm_head\n",
    "from tokenization import Vocab\n",
    "from ete3 import Tree\n",
    "from Bio import Phylo\n",
    "import os\n",
    "from scipy.spatial.distance import squareform, pdist, cdist\n",
    "\n",
    "\n",
    "# from libc.time cimport time\n",
    "# from cython.parallel import prange\n",
    "\n",
    "def greedy_select(msa: List[Tuple[str, str]], num_seqs: int, mode: str = \"max\") -> List[Tuple[str, str]]:\n",
    "    assert mode in (\"max\", \"min\")\n",
    "    if len(msa) <= num_seqs:\n",
    "        return msa\n",
    "    \n",
    "    array = np.array([list(seq) for _, seq in msa], dtype=np.bytes_).view(np.uint8)\n",
    "\n",
    "    optfunc = np.argmax if mode == \"max\" else np.argmin\n",
    "    all_indices = np.arange(len(msa))\n",
    "    indices = [0]\n",
    "    pairwise_distances = np.zeros((0, len(msa)))\n",
    "    for _ in range(num_seqs - 1):\n",
    "        dist = cdist(array[indices[-1:]], array, \"hamming\")\n",
    "        pairwise_distances = np.concatenate([pairwise_distances, dist])\n",
    "        shifted_distance = np.delete(pairwise_distances, indices, axis=1).mean(0)\n",
    "        shifted_index = optfunc(shifted_distance)\n",
    "        index = np.delete(all_indices, indices)[shifted_index]\n",
    "        indices.append(index)\n",
    "    indices = sorted(indices)\n",
    "    return [msa[idx] for idx in indices]\n",
    "\n",
    "@cython.cdivision(True)\n",
    "cdef inline int randint(int lower, int upper) nogil:\n",
    "\n",
    "    return rand() % (upper - lower) + lower\n",
    "\n",
    "class Creation_MSA_Generation_MSA1b_Cython:\n",
    "\n",
    "    # cdef int n_rows\n",
    "    # cdef int n_cols\n",
    "    \n",
    "    def __init__(self, MSA, start_seq_index = 0,full_tree = None, full_tree_path = None):\n",
    "\n",
    "        if start_seq_index != 0:\n",
    "            start_seq = MSA[start_seq_index]\n",
    "            del MSA[start_seq_index]\n",
    "            MSA = [start_seq] + MSA\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        self.original_MSA = MSA\n",
    "        self.full_tree = full_tree\n",
    "        self.full_tree_path = full_tree_path\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.n_rows = len(self.original_MSA)\n",
    "        self.n_cols = len(self.original_MSA[0][1])\n",
    "        \n",
    "        self.model, self.alphabet = esm.pretrained.esm_msa1b_t12_100M_UR50S()\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model_alphabet_mapping = self.alphabet.to_dict()\n",
    "        self.model_alphabet_mapping_inv = dict(zip(range(len(self.alphabet.all_toks)), self.alphabet.all_toks))\n",
    "        self.batch_converter = self.alphabet.get_batch_converter()\n",
    "        self.model.eval() \n",
    "\n",
    "        # base_state_dict = {}\n",
    "        # for name, param in self.model.state_dict().items():\n",
    "        #     if not (name.startswith(\"lm_head\") or name.startswith(\"contact_head\")):\n",
    "        #         base_state_dict[name] = param\n",
    "        \n",
    "        # lm_head_state_dict = {}\n",
    "        # for name, param in self.model.state_dict().items():\n",
    "        #     if name.startswith(\"lm_head\") or name == \"embed_tokens.weight\":\n",
    "        #         lm_head_state_dict[name] = param\n",
    "\n",
    "        # self.msa_light = MSATransformer(vocab = Vocab.from_esm_alphabet(self.alphabet))\n",
    "        # self.msa_light = self.msa_light.to(self.device)\n",
    "        \n",
    "        # self.msa_lm_head = MSATransformer_lm_head(vocab = Vocab.from_esm_alphabet(self.alphabet))\n",
    "        # self.msa_lm_head = self.msa_lm_head.to(self.device) \n",
    "\n",
    "        # self.msa_light.load_state_dict(base_state_dict, strict=True)\n",
    "        # self.msa_lm_head.load_state_dict(lm_head_state_dict, strict=True)\n",
    "\n",
    "        _,_,self.context = self.batch_converter([self.original_MSA[1:]])\n",
    "        self.context = self.context.to(self.device)\n",
    "        \n",
    "        _,_,self.init_seq = self.batch_converter([self.original_MSA[:1]])\n",
    "        self.init_seq = self.init_seq.to(self.device)\n",
    "\n",
    "        # del self.model\n",
    "    \n",
    "    def prob_calculator(self, batch_tokens, selected_pos, method = \"minimal\", masked = False):\n",
    "        \n",
    "        softmax = torch.nn.Softmax(dim = -1)\n",
    "\n",
    "        batch_tokens_copy = batch_tokens.clone()\n",
    "        original_char_index = batch_tokens[0,0,selected_pos] \n",
    "        \n",
    "        if masked == True:\n",
    "            batch_tokens_copy[0,0,selected_pos] = self.model_alphabet_mapping[\"<mask>\"]\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "\n",
    "            # original_char_prob = (softmax(self.msa_lm_head(self.msa_light(batch_tokens_copy)[0,0,selected_pos,:])).cpu().numpy())[original_char_index]\n",
    "            original_char_prob = (softmax(self.model(batch_tokens_copy)[\"logits\"][0,0,selected_pos,:]).cpu().numpy())[original_char_index]\n",
    "        \n",
    "            if method == \"minimal\":\n",
    "\n",
    "                return np.log(original_char_prob)\n",
    "                  \n",
    "            if method == \"full\" or method == \"row\":\n",
    "\n",
    "                # probs = softmax(self.msa_lm_head(self.msa_light(batch_tokens_copy)[0,0,:,:])).cpu().numpy()\n",
    "                probs = softmax(self.model(batch_tokens_copy)[\"logits\"][0,0,:,:]).cpu().numpy()\n",
    "                          \n",
    "                log_prob_row = 0\n",
    "                \n",
    "                for i in range(1,self.n_cols +1):\n",
    "                    char_index = batch_tokens[0,0,i]\n",
    "                    log_prob_row += np.log(probs[i,char_index])\n",
    "    \n",
    "                if method == \"row\":\n",
    "    \n",
    "                    return log_prob_row\n",
    "                                               \n",
    "            if method == \"full\" or method == \"col\":\n",
    "\n",
    "                log_prob_col = 0\n",
    "    \n",
    "                # probs = softmax(self.msa_lm_head(self.msa_light(batch_tokens_copy)[0,:,selected_pos,:])).cpu().numpy()\n",
    "                probs = softmax(self.model(batch_tokens_copy)[\"logits\"][0,:,selected_pos,:]).cpu().numpy()\n",
    "\n",
    "                for i in range(self.n_rows):\n",
    "                    char_index = batch_tokens[0,i,selected_pos]\n",
    "                    log_prob_col += np.log(probs[i,char_index])\n",
    "    \n",
    "                if method == \"col\":\n",
    "    \n",
    "                    return log_prob_col\n",
    "    \n",
    "            log_total_prob = log_prob_row + log_prob_col - np.log(original_char_prob)\n",
    "\n",
    "        return log_total_prob\n",
    "\n",
    "    def generate_subtree(self,leaves,full_tree, full_tree_path):\n",
    "        \n",
    "        MRCA = full_tree.common_ancestor(leaves)\n",
    "        \n",
    "        t = Tree(self.full_tree_path)\n",
    "        t.prune(leaves, preserve_branch_length=True)\n",
    "        t.write(outfile='temp_sub.tree')\n",
    "        \n",
    "        subtree =  Phylo.read(\"temp_sub.tree\",\"newick\")\n",
    "        os.remove(\"temp_sub.tree\")\n",
    "        \n",
    "        if full_tree.distance(MRCA.root) != 0:\n",
    "            subtree.clade.branch_length = full_tree.distance(MRCA.root)\n",
    "\n",
    "        return subtree\n",
    "\n",
    "    def msa_tree_phylo(self, clade_root, flip_before_start = 0, method = \"minimal\", masked = False, context_type = \"static\"):\n",
    "                \n",
    "        self.phylogeny_MSA = []\n",
    "        \n",
    "        first_sequence_tokens = self.mcmc(flip_before_start, self.init_seq)\n",
    "        if context_type == \"static\":\n",
    "            self.msa_tree_phylo_recur(clade_root, first_sequence_tokens, method, masked)\n",
    "        elif context_type == \"dynamic\":\n",
    "            self.msa_tree_phylo_recur_dynamic(clade_root, first_sequence_tokens, method, masked)\n",
    "\n",
    "        results = self.phylogeny_MSA.copy()\n",
    "        self.phylogeny_MSA = []\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def msa_tree_phylo_chunked(self, total_sequences, sequences_per_iteration, method = \"minimal\", masked = False):\n",
    "\n",
    "        phylogeny_MSA_chunked = []\n",
    "\n",
    "        all_sequences = self.original_MSA.copy()\n",
    "        number_of_iterations = int(total_sequences/sequences_per_iteration)\n",
    "\n",
    "        for i in range(number_of_iterations):\n",
    "\n",
    "            selected_sequences = greedy_select(all_sequences, num_seqs=sequences_per_iteration)\n",
    "            selected_sequences_names = [elem[0] for elem in selected_sequences]\n",
    "            not_selected_sequences_ind = [i for i in range(len(all_sequences)) if all_sequences[i][0] not in selected_sequences_names]\n",
    "\n",
    "            tree = self.generate_subtree(selected_sequences_names, self.full_tree, self.full_tree_path)\n",
    "\n",
    "            Phylo.draw(tree)\n",
    "            \n",
    "            _,_,self.context = self.batch_converter([selected_sequences[1:]])\n",
    "            self.context = self.context.to(self.device)\n",
    "        \n",
    "            _,_,self.init_seq = self.batch_converter([selected_sequences[:1]])\n",
    "            self.init_seq = self.init_seq.to(self.device)\n",
    "\n",
    "            if tree.clade.branch_length != None:\n",
    "                flip_before_start = tree.clade.branch_length*self.n_cols\n",
    "            else:\n",
    "                flip_before_start = 0\n",
    "                \n",
    "            simulated_chunk_seqs = self.msa_tree_phylo(tree.clade, flip_before_start=flip_before_start, method=method, masked=masked)\n",
    "            phylogeny_MSA_chunked += simulated_chunk_seqs\n",
    "\n",
    "            all_seq_copy = all_sequences.copy()\n",
    "            all_sequences = [all_seq_copy[i] for i in not_selected_sequences_ind]\n",
    "\n",
    "            del all_seq_copy\n",
    "\n",
    "        return phylogeny_MSA_chunked\n",
    "    \n",
    "    def msa_tree_phylo_recur(self, clade_root, previous_sequence_tokens, method = \"minimal\", masked = False):\n",
    "        \n",
    "        b = clade_root.clades\n",
    "        \n",
    "        if len(b)>0:\n",
    "            for clade in b:\n",
    "                #Mutation on previous_sequences\n",
    "                print(\"entering new branch\")\n",
    "                n_mutations = clade.branch_length*self.n_cols\n",
    "                new_sequence_tokens = self.mcmc(n_mutations, previous_sequence_tokens, method, masked)\n",
    "                self.msa_tree_phylo_recur(clade, new_sequence_tokens, method, masked)\n",
    "        else:\n",
    "\n",
    "            final_seq = \"\"\n",
    "            for i in range(1,self.n_cols+1):\n",
    "\n",
    "                char_index = int(previous_sequence_tokens[0,0,i].cpu().numpy())\n",
    "                character = self.model_alphabet_mapping_inv[char_index]\n",
    "                final_seq += character\n",
    "                            \n",
    "            seq_index = len(self.phylogeny_MSA)\n",
    "            self.phylogeny_MSA.append((f\"seq{seq_index}\",final_seq))\n",
    "            \n",
    "    def msa_tree_phylo_recur_dynamic(self, clade_root, previous_sequence_tokens, method = \"minimal\", masked = False, context_size = 9):\n",
    "        \n",
    "        b = clade_root.clades\n",
    "        print(b)\n",
    "        \n",
    "        if len(b)>1:\n",
    "            for clade in b:\n",
    "                #Mutation on previous_sequences\n",
    "                print(\"entering new branch\")\n",
    "                n_mutations = clade.branch_length*self.n_cols\n",
    "                desc_leaves = [node.name for node in clade.get_terminals()]\n",
    "                print(desc_leaves)\n",
    "                self.context = [elem for elem in self.original_MSA if elem[0] in desc_leaves]\n",
    "                if len(self.context) > context_size:\n",
    "                    \n",
    "                    random_ind = list(np.random.choice(range(len(self.context)),context_size, replace = False))\n",
    "                    self.context = list(np.array(self.context)[random_ind])\n",
    "\n",
    "                chosen_leaves = [elem[0] for elem in self.context]\n",
    "                \n",
    "                _,_,self.context = self.batch_converter([self.context])\n",
    "                self.context = self.context.to(self.device)\n",
    "                \n",
    "                new_tree = self.generate_subtree(desc_leaves,self.full_tree,self.full_tree_path)\n",
    "                new_sequence_tokens = self.mcmc(n_mutations, previous_sequence_tokens, method, masked)\n",
    "                self.msa_tree_phylo_recur_dynamic(new_tree.clade, new_sequence_tokens, method, masked)\n",
    "        else:\n",
    "\n",
    "            final_seq = \"\"\n",
    "            for i in range(1,self.n_cols+1):\n",
    "\n",
    "                char_index = int(previous_sequence_tokens[0,0,i].cpu().numpy())\n",
    "                character = self.model_alphabet_mapping_inv[char_index]\n",
    "                final_seq += character\n",
    "                            \n",
    "            print(final_seq)\n",
    "            seq_index = len(self.phylogeny_MSA)\n",
    "            self.phylogeny_MSA.append((f\"seq{seq_index}\",final_seq))\n",
    "    \n",
    "    @cython.cdivision(True)\n",
    "    def mcmc(self, Number_of_Mutation, previous_sequence_tokens, method = \"minimal\", masked = False):  \n",
    "    \n",
    "        cdef:\n",
    "            int c_mutation = 0\n",
    "            int tot_mutations = Number_of_Mutation\n",
    "            float de\n",
    "\n",
    "        print(f\"Number of mutations: {tot_mutations}\")\n",
    "        proposals = 0\n",
    "        \n",
    "        while c_mutation<tot_mutations:\n",
    "\n",
    "            stacked_tokens = torch.cat((previous_sequence_tokens, self.context), dim = 1)\n",
    "            \n",
    "            selected_pos = np.random.randint(1, self.n_cols + 1)\n",
    "\n",
    "            orig_log_prob = self.prob_calculator(stacked_tokens, selected_pos, method, masked)\n",
    "            \n",
    "            original_character_int = previous_sequence_tokens[0,0, selected_pos].cpu().numpy()        \n",
    "            \n",
    "            proposed_mutation = np.random.randint(4, 24)\n",
    "\n",
    "            proposals += 1\n",
    "\n",
    "            if proposed_mutation >= original_character_int:\n",
    "                proposed_mutation += 1\n",
    "            \n",
    "            if proposed_mutation == 24:\n",
    "                proposed_mutation = 30\n",
    "\n",
    "            modified_sequence_tokens = previous_sequence_tokens.clone()\n",
    "            modified_sequence_tokens[0,0,selected_pos] = proposed_mutation\n",
    "            modified_stacked_tokens = torch.cat((modified_sequence_tokens, self.context), dim = 1)\n",
    "\n",
    "            assert int((modified_stacked_tokens != stacked_tokens).sum().cpu().numpy()) == 1\n",
    "            assert modified_stacked_tokens[0,0,selected_pos] != stacked_tokens[0,0,selected_pos]\n",
    "            \n",
    "            new_log_prob = self.prob_calculator(modified_stacked_tokens, selected_pos, method, masked)\n",
    "\n",
    "            # assert (self.arr_check_1 == self.arr_check_2).all()\n",
    "            \n",
    "            de = new_log_prob - orig_log_prob\n",
    "                \n",
    "            if (de >= 0) | (np.random.uniform() < exp(de)):\n",
    "                previous_sequence_tokens = modified_sequence_tokens.clone()\n",
    "                c_mutation += 1\n",
    "\n",
    "        print(f\"Number of proposals: {proposals}\")\n",
    "        \n",
    "        return previous_sequence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05c4c1-ec1e-4cea-bccb-11b11b187de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_path = f\"{MSA_filename}_sampled_{num_seqs}_rooted.tree\"\n",
    "tree = Phylo.read(tree_path,\"newick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7775ec11-f194-4115-9787-6849c33da730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize = (20,20))\n",
    "Phylo.draw(tree, axes = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02ba1f-f82c-47fd-831e-37fab9a68635",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSA_gen_obj = Creation_MSA_Generation_MSA1b_Cython(MSA = sampled_MSA_tuples,full_tree=tree,full_tree_path=tree_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4ee06-3e68-4715-8402-f2399d719d92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1 = time()\n",
    "new_MSA = MSA_gen_obj.msa_tree_phylo(tree_100.clade,flip_before_start=0, method=\"minimal\", masked=True, context_type=\"dynamic\")\n",
    "t2 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecbf5ec-9ff1-4ced-b33e-48abedd54c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time()\n",
    "new_MSA = MSA_gen_obj.msa_tree_phylo_chunked(total_sequences=100,sequences_per_iteration=2,method=\"minimal\", masked=False)\n",
    "t2 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7798ec-f1f9-4ec1-90a3-585c8a2cf180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize = (20,20))\n",
    "Phylo.draw(tree_100, axes = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc68a653-cc73-4f28-abcc-533edf01441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list(np.array([1,2,3])[[1,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef32fc95-dba2-42d2-b4dc-04af587b2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "type('sample58')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab938338-b59d-4a1f-94a2-164d42f91982",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phylo.clade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cfd12f-309e-4eaf-8f80-ca5d1a98404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSA_name = \"divided-msa-full\"\n",
    "Seq_tuples_to_fasta(new_MSA,MSA_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d72b0-dd86-4f3a-83c4-72bcd0203123",
   "metadata": {},
   "outputs": [],
   "source": [
    "(t2-t1)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f47f8-e40d-449b-baf7-e4d212cb02d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats\n",
    "from pstats import SortKey\n",
    "p = pstats.Stats('cProfile_stats')\n",
    "p.strip_dirs().sort_stats('cumtime').print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04998ba0-0807-45e4-a7f3-c3e7895a91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_probs = np.load(\"accepted_probs.npy\")\n",
    "orig_probs = np.load(\"orig_probs.npy\")\n",
    "probs_ratio = np.load(\"probs_ratio.npy\")\n",
    "\n",
    "all_probs_df = pd.DataFrame({\"accepted_probs\":accepted_probs, \"orig_probs\":orig_probs, \"probs_ratio\":probs_ratio})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad181c3b-50ed-415f-9652-54b03ab7a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b036b-b88f-4694-ab1f-ee569f2bd8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9739c-f464-4036-a2e4-81798b24b73b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3,ncols = 1, figsize = (10,15))\n",
    "\n",
    "all_probs_df.hist(\"accepted_probs\",bins = 40, ax = axes[0])\n",
    "all_probs_df.hist(\"orig_probs\",bins = 40, ax = axes[1])\n",
    "all_probs_df.loc[all_probs_df[\"probs_ratio\"] < 1, :].hist(\"probs_ratio\",bins = 40, ax = axes[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9b0a8-9622-4d7b-8693-f9692ae179ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_probs_df.loc[all_probs_df[\"probs_ratio\"] < 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dba516-9617-42b8-98c8-ededfdd77be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac4cf8-0ede-41eb-8ecc-37fea9e577f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29.90259865919749 - using rand() C function (minimal)\n",
    "# 35.093829254309334 - using np.random.uniform (minimal)\n",
    "# 29.68756223519643 - using full model instead of msa_light and msa_lm_head (minimal)\n",
    "# 31.15256113608678 - using full model with cdivision (minimal)\n",
    "# 26.35336556037267 - using divided model with cdivision (minimal)\n",
    "# 26.2116673151652 - using divided model with cdivision (full)\n",
    "# 317.65937532981235 - using divided model with cdivision (full) and 100 sequences\n",
    "# 829 - using standard model and minimal-masking mode with 100 sequences- \n",
    "# 26.54462937116623 using standard model and \"reducing, randomly sampled context\" to generate 100 seqs along big tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
